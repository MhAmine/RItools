\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{natbib}
\begin{document}

<<>>=
set.seed(20151001)
library(testthat)
@ 



\section{Purposes and premises: Descriptive stats}




This document lays out calculations behind
\texttt{xBalance}'s ``descriptives,'' e.g. means and SDs of the groups
being compared, with allowances for missing values, clustering,
stratification, stratum weights, ie weights associating with each of a
collection of strata that serve to define a ``standard population,''
amd element weights, ie weights associating with elements,
deaggregated units of observation.  In the same display and output
\texttt{xBalance}  furnishes additional statistics, ``inferentials'',
designed under somewhat different premises (and laid out in a separate
document).  Its z statistics, p values and chisquare statistics all
fall under the Inferential banner.

Our descriptives aim to describe the sample as simply as is possible
while being consistent with the user's stated design.   For both
treatment and control samples, the descriptives are calculated in such
a way as to estimate the corresponding quantity in the study
population: treatment and control group means both estimate study
population means; treatment and control group SDs both estimate study
population SDs.  (More specifically, if strata are present they
estimate an appropriately means/SDs within a standard population based
on the study population, with standardization weights equal to those
specified via \texttt{stratum.weights}.)   

In order to present treatment and control group averages that can
properly be described as such, we use ``ratio estimates,'' as opposed
to the intrinsically unbiased Horwitz-Thompson-type estimates, which
do not in general line up with wieghted means of observations under
any coherent weighting scheme. (They are weighted sums across the
sample divided by sums of weights across the broader population. These
weights are a little different, but still the numerator weights
needn't add up to the same thing as the denominator weights.)  Our
treatment group average is the ratio of a weighted sum of treatment
group observations divided by the sum of treatment group weights, or
equivalently the ratio of Horwitz-Thompson-type estimates,
extrapolated from the sample of the treatment group to the population
of the study group as a whole, of the population total of the variable
and of the population size.  Similarly our control group average is a
ratio of HT estimates of means projected from the sample of the
control group out to the study population as a whole; and our
treatment and control group variances are based on HT estimates of
second moments, extrapolated out from the treatment and control groups
respectively.

Unlike Horwitz-Thomson estimates, ratio estimates are subject to
finite-sample bias.  denominator sum and the numerator sum are both
sums within \textit{and across} strata: these are ``combined ratio''
estimates. (Combined ratio estimators are consistent under weaker
assumptions than those required for ``separate ratio'' estimators.)

Our descriptives will also avoid imputation of missing values.
Instead they can be viewed as downweighting missing observations to 0,
while adding a check for differences between the two groups in terms
of the presence of missing values.  There's a tension between the
first of these maneuvers and interpretations of weights as inclusion
or assignment probabilities; that tension is addressed below, in
Section~\ref{sec:element-weights}.

\subsection{Simple strata, no element weights or clusters}


Let \texttt{X} be a (model) matrix of covariates with dimension $n \times
p$. For computational reasons, in each column with missing values these NAs will have been replaced with a single reference value; however, the locations of these imputations are recorded indirectly in a separate matrix of the same dimensions, \texttt{NotMissing}. 
%% (this varies from our previous missingness indicators that will only have a column for each variable that is missing. We need to expand to get the matrix ops to work out. Also, since the we've already done model matrix expansion, we'll need a matrix that corresponds to missingness in the original variable, so many columns many be indentical as they represent the same categorical variable). 

\texttt{S} is a $n \times s$ (sparse) matrix indicating membership in the $s$
strata. It may be the case that some units are not in any stratum.   $Z$ is a vector of treatment assignment. 
Furthermore, all strata have at least one treated and at least one control (if not we set members of those strata to zero everywhere).


Some examples to check that we get what we want. 2 sets of 3 and one
set of 2. We'll use column matrices to make sure we have the right
dimensions everywhere. We'll make group~3's treated unit missing a value on
$X_1$ (but not other $X$), both of group~2's treated units missing on
$X_2$ but not other $X$es, and both of group~1's control units missing on $X_3$. 
Nothing missing on $X_4$.  
<<>>=
X <- matrix(rnorm(32), nrow = 8)
colnames(X) <- paste0("X", 1:4)

Z <- c(1,0,0,1,1,0,0,1) 
S <- matrix(c(rep(c(1,0,0), 3), rep(c(0,1,0), 3), rep(c(0,0,1), 2)), nrow = 8, byrow = T)
colnames(S) <- letters[1:3]
cbind("Z"=Z, S)

missing <- matrix(c(0,0,0,0,0,0,0,1, # X_1
               0,0,0,1,1,0,0,0, # X_2
               0,1,1,0,0,0,0,0, # X_3
               0,0,0,0,0,0,0,0),# X_4
             nrow = 8)
colnames(missing) <- colnames(X)
NotMissing <- 0 + !missing #we prefer a numeric matrix, 
NotMissing                 #for upcoming generalizations
@ 


\subsubsection{Means \& mean differences}

For each variable we want to drop any units in
strata that have all missing treated or all missing control. 

<<>>=

ZZ <-  S * Z # this matrix indicates which units are treated, by stratum
WW <-  S * !Z # which units are control, again by stratum 
S.missing.1s <- t(ZZ) %*% NotMissing ==0 # result is s * p
S.missing.0s <- t(WW) %*% NotMissing == 0# s * p also
( S.has.both <- 0 + # again we prefer a numeric to a logical matrix
     !(S.missing.0s | S.missing.1s)  # coercion to logical treats pos values as TRUE
 )

@ 

At the end of the day, we want a matrix that is $n \times p$, where $p$ is
the number of variables we're considering.
<<>>=
use.units <- (S %*% S.has.both) # n * p
use.units <- use.units * NotMissing
@ 


Counts of non-missing observations, separately for treatment
and control:
<<>>=
n1 <- t(use.units) %*% Z # p * 1
n0 <- t(use.units) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 


Deal with missing values.
<<>>=

X.use  <- X * use.units

@ 

Means of non-missing observations in the treatment group.
<<>>=
treated.avg <- t(X.use) %*% Z / n1 # p * 1

@ 

Which is basically the same as what \texttt{mean(\ldots, na.rm=T)} would
have delivered:
<<>>=

zapsmall(treated.avg -
    apply(ifelse(NotMissing * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          )
         )==0


@ 
The discrepancy for \texttt{X3} being caused by its lacking \textit{control}
group observations in stratum a, which for this reason gets dropped
from the calculation:
 
<<>>=
S.missing.1s

expect_true(all( abs(treated.avg -
    apply(ifelse(use.units * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          ))<=.Machine$double.eps^.5
         ) )

@ 



To determine a weighting scheme with which to prepare corresponding
control group  averages, we can use the treatment group
as the standard population, so that the contributions from a given
stratum are up-or down-weighted in proportion to the fraction of the
stratum assigned to treatment.   Specifically, a weighting factor
equal to the odds of assignment to treatment is to be applied to each
control.  (This assumes assignment probabilities never vary within a stratum.)

Here are these factors, by stratum and variable: 
<<>>=
Z.odds <- ( t(ZZ) %*% use.units ) / ( t(WW) %*% use.units )
( Z.odds <- ifelse(S.has.both, Z.odds, 0) ) # s * p
@
Note that strata which don't admit of a
comparison have to be explicitly dropped, via \texttt{S.has.both}.

An earlier reference implementation 
uses the name \texttt{ETT} (for ``effect of treatment on treated'') for the element by variable
representation of these weights: 
<<>>=
ETT <- S %*%  Z.odds  # n * p
@ 

So the ETT-weighted averages of the control group are
<<>>=
n0.ett <- t( use.units * ETT ) %*%  (1 - Z) 
(control.avg <- t(X.use * ETT ) %*% (1 - Z) / n0.ett)
@ 

\subsubsection{Scale \& scaled mean differences}
Next up, pooled standard deviations.  

<<>>=
X2.use <- X^2 * use.units # same exclusions as w/ X1.use
var.1 <- ( t(X2.use) %*% Z - n1 * treated.avg^2 )/(n1 -1 )
var.0 <- ( t(X2.use * ETT) %*% (1 - Z) - n0.ett * control.avg^2 )/n0.ett
var.0 <- var.0 * n0/(n0-1)
@ 

Comparing to the unweighted, pooled variances calc (which isn't really
expected to give the same thing):
<<>>=

(pooled <- sqrt((var.1*(n1-1) + var.0*(n0-1)) / (n1 + n0 - 2)))
apply(ifelse(use.units, 
             X, NA_real_), 
      2, function(var) summary(lm(var~Z))$sigma )
@


The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 

\subsection{Stratum weights and other complications}


To generalize our stratum combination scheme above in order to get corresponding averages for
controls, we conceptualize the weight attaching to each
unit as the product of a  Horwitz-Thompson type inverse probability
of assignment weight and a stratum weight, which may have been
communicated by the user.   By default, the stratum
weights are prortional to the
number of units assigned to treatment in that stratum. In the absence
of element weights, for treatment
group members the product of these two factors is 1, as above; for controls,
it's the ``treatment odds'' or a priori odds of assignment to
treatment.  The treatment group is in effect serving to define a standard
population. This scheme has the advantage of culminating naturally in
treatment and control group means that are each interpretable as a 
combined ratio estimates of means over that standard population.

%% The operations of stratum weighting (``ETT'') and kicking out strata
%% that don't admit of a comparison should be unified.  This will
%% simplify the calculations and make it easier to create a slot for
%% alternate weighting schemes.\ldots


(At 9a84617 this writeup fell a little behind the development w/in the
clusters branch; there weights for both treatments and controls are
calculated explicity from a combo of aggregated element weights and
stratum weights.)



\subsection{Element weights} \label{sec:element-weights}

Now let's suppose that, separate from any stratum weights, the user
has communicated observation-specific weights. These weights are assumed invariant to treatment
assignment.  For reasons to be explained with the extension to
clustering, to distinguish these weights from stratum weights we'll
call them element weights.  The element weights may represent proportions of a target
population that a given observation is to be taken to
represent, as the would if the study population were in fact a
probability sample, and the weights were determined as reciprocals of
sample inclusion probabilities. 

Now we have two sets of weights to take into account, the element or
inclusion weights and the assignment weights mentioned in the
previous section. Our basic response is to multiply the two sets of
weights together. 

As mentioned above, our descriptives can be viewed as downweighting missing
observations to 0.   This sort of selective weighting is at odds with
Horwitz-Thompson interpretations of weights --- as reciprocals of
sample inclusion and/or treatment assignment probabilities, or perhaps
products thereof --- but this interpretation will be rescued in the
following way.  First, anytime we observe a missing observation in \texttt{myvar} we
place a 1 in that row of \texttt{myvar.NA}, a variable constructed by
us; balance calculations are presented for this variable as well as
for \texttt{myvar}.  Second, we consider our ratio estimator to be the
ratio of HT estimates of the study population totals of \texttt{myvar
  * !myvar.NA}, and \texttt{!myvar.NA}, respectively.  


A computational issue, to be addressed: as of this writing we're not
properly adjusting for weights in our calls to
\texttt{slm.fit.csr.corrected()}: rather than upweighting Covs by
weights, we should upweight them and the design matrix both by
square-rooted weights, or in some other way sneak a diagonal matrix of
weights in between the $Y'$ and the $X$ and in between the $X'$ and the
$X$. See e.g. \texttt{slm.wfit.csr}.  But note that in that code there
doesn't appear to be any allowance made for having used an upweighted
Y and upweighted design matrix in fitting once it's time to extract
fitted values or residuals; a correction appears to be needed. 

\subsubsection{Means \& mean differences}
We need to make \emph{per-variable} element weights,
``\texttt{pv.c.wt},'' products of user-provided element weights (implicit
$1$'s when the user hasn't specified a weight) and per-variable
missingness indicators. 

<<>>=
element.weights <- rep(1,8) # for now
pv.c.wt <- use.units * element.weights
@ 

This time the moment calculations begin as follows.% reorganize this for coherence
                                      %w/ subsequent blocks?

<<>>=

X.use  <- X * pv.c.wt
X2.use <- X * X.use

@ 
Note that \texttt{pv.c.wt} is doing two things here, imposing element
weights on a per-variable basis plus zeroing out the missing entries.
We'll do the same thing to calculate ``\texttt{n1}'' and
``\texttt{n0}.''   This is now an abuse of notation, however, since
they're not sample sizes but per variable sums of element weights:
<<>>=
n1 <- t(pv.c.wt) %*% Z # p * 1
n0 <- t(pv.c.wt) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 
(When we start with constant element weights, \texttt{n1} differences across variables are
due entirely to differences in missingness patterns [and similarly for
\texttt{n0}].)

To compute weighted means over the 
treatment group, applying element weights
and downweighting missing items to 0 
(but with no adjustment for strata), do:
<<>>=
(treated.avg <- t(X.use) %*% Z / n1) # p * 1
@ 

ETT weighting factor (by element and variable) are computed as follows.
<<>>=
Z.odds <- ( t(ZZ) %*% use.units ) / ( t(WW) %*% use.units )
( Z.odds <- ifelse(S.has.both, Z.odds, 0) ) # s * p
(ETT <- S %*% Z.odds) # n * p
@ 

Notice that the element weights don't come into play yet -- this
weighting factor is separated from those weights, which on the other
hand get baked directly into \texttt{X.use}, \texttt{X2.use}.

Now weighted averages of the control group, using the weighted
treatment group as a standard population, are computed by:

<<>>=
n0.ett <- t( pv.c.wt * ETT ) %*%  (1 - Z) 
(control.avg <- t(X.use * ETT ) %*% (1 - Z) / n0.ett)
@ 

\subsubsection{Scale \& scaled mean differences}

Next up, pooled standard deviations. 

<<>>=
X2.use <- X^2 * pv.c.wt # same exclusions as w/ X1.use
var.1 <- ( t(X2.use) %*% Z - n1 * treated.avg^2 )/(n1 -1 )
var.0 <- ( t(X2.use * ETT) %*% (1 - Z) - n0.ett * control.avg^2 )/n0.ett
var.0 <- var.0 * n0/(n0-1)
@ 

Comparing to the unweighted, pooled variances calc (which isn't really
expected to give the same thing):
<<>>=

(pooled <- sqrt((var.1*(n1-1) + var.0*(n0-1)) / (n1 + n0 - 2)))
apply(ifelse(use.units, 
             X, NA_real_), 
      2, function(var) summary(lm(var~Z))$sigma )
@


The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 


\subsection{Clusters}

The intention of the design for calcs with strata and element weights,
above, is that these adaptations will address clusters also, by dint of the following.

\begin{quote}
  \textit{Assumptions.}  If the user specified a clustering variable
  alongside of an element-by-variable table (and potentially element
  weights), then that data frame 
  has already been processed into cluster-by-variable matrices
  \texttt{X} and \texttt{pv.c.wt}. Furthermore
  \begin{enumerate}
  \item \label{item:0} Each \texttt{X} entry represents a weighted \textit{mean}
    over the non-missing values of the variable for the cluster in
    question, with weights equal to user-provided element weights. 
  \item Each \texttt{pv.c.wt} entry records a \textit{sum} of
    user-provided element
    weights, over elements within the cluster for which the variable
    was not missing.
  \end{enumerate}
\end{quote}
(\ref{item:0} might equally well have used weighted sums as opposed to
weighted means. I favor this convention mostly for future-proofing: we
may at some point wish to enable merges of cluster-level data frames
with Design objects we've aggregated from element to cluster level.)


\texttt{C} is a $n \times c$ (sparse) matrix indicating cluster membership with 1, zero otherwise for $c$ clusters. 
Each row of \texttt{C} has one and only one finite entry. We can assume it has been validated that all members of the same cluster have the same $Z_i$ value and all clusters are nested within strata.

\section{Purposes and premises: Inferential statistics}


Here we calculate the ``adjusted differences,'' ``combined
differences'' and associated $p$-values  of \citet{hansen:bowers:2008}, but with a couple additional wrinkles
to handle missingness.  Given strata $1, \ldots, B$, stratum weights
$\{w_{b}\}$; for each stratum $b$ a length-$n_{b}$ treatment
assignment vector $\mathbf{Z}_{b}$, an $n_{b} \times p$ matrix
$\mathbf{x}_{b} $ of cluster \textit{totals}, and an $n_{b}$-vector
$\mathbf{m}_{b}$ of cluster sizes, the adjusted mean difference was
\begin{equation*}
  d(\mathbf{Z}, \mathbf{x}) = \sum_{b=1}^B w_b \left\{  \mathbf{Z}_{b}'
                       \mathbf{x}_{b}/(\bar{m}_{b} n_{tb}) -
(\mathbf{1} - \mathbf{Z}_{b})'\mathbf{x}_{b}/[\bar{m}_{b}(n_{b} - n_{tb})] \right\} 
\end{equation*}
or, equivalently,
\begin{equation}\label{eq:HB08eq4}
   d(\mathbf{Z}, \mathbf{x}) = \sum_{b=1}^B w_b h_b^{-1} \bar{m}_b^{-1} \mathbf{Z}_{b}' \mathbf{x}_{b} - \sum_{b=1}^B w_b
  \bar{m}_b^{-1} (n_b - n_{tb})^{-1} \mathbf{1}'\mathbf{x}_{b}  , 
\end{equation}
where $h_{b} = n_{tb}(n_{b} - n_{tb})/n_{b} = [n_{tb}^{-1} + (n_{b} -
n_{tb})^{-1}]^{-1}$ is half the harmonic mean of the sizes of the
treatment and control groups --- in terms of clusters, not elements
--- in stratum $b$.  

The additional wrinkles to handle missingness:
\begin{enumerate}
\item Cluster size $m_{bi}$ is replaced by the more general $w_{bi} $, indicating the sum of weights of
  non-NA elements within the cluster $i$ of stratum $b$. 
\item In addition, $w_{bi}$ is allowed to differ for different
  variables, following different missingness patterns.  So instead of
  $n_{b}$-vectors $\mathbf{m}_{b}$ we have $m \times p$ matrices $\mathbf{w}_{b}$; also
  $\bar{w}_{b}$ is a $p$-vector.
\item To avoid a notation conflict, the stratum weights of
  \eqref{eq:HB08eq4} will be denoted as $s_{b}$, not $w_{b}$.  (And
  they'll soon be supplanted anyway.)
\item In addition, we'll think of the $\mathbf{x}_{b} $'s
  as matrices of weighted \textit{means}, not totals, with weight
  matrices $\mathbf{w}_{b} $ standing in the background.  
\end{enumerate}

With these modifications, with $\mathbf{x}_{(j)}$, $\mathbf{x}_{b(j)}$ used to indicate
the $j$th column of $\mathbf{x} $ and $\mathbf{x}_{b} $ respectively,
and with $\mathbf{a} \cdot \mathbf{b} $ used to indicate the
element-wise product of similarly dimensioned vectors or matrices $\mathbf{a}$
and $\textbf{b}$, adjusted mean differences are expressible as
\begin{align}
  d(\mathbf{Z}, \mathbf{x}_{(j)}) &= \sum_{b=1}^B s_b \left\{  \mathbf{Z}_{b}'
                       (\mathbf{x}_{b(j)} \cdot \mathbf{w}_{b(j)})/(\bar{w}_{b(j)} n_{tb}) -
(\mathbf{1} -
                                    \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
                                    \mathbf{w}_{b(j)})/[\bar{w}_{b(j)}(n
                                    - n_{tb})] \right\} \label{eq:0}  \\
  &= \sum_{b=1}^B s_b h_b^{-1} \bar{w}_{b(j)}^{-1} \mathbf{Z}_{b}'
    (\mathbf{x}_{b(j)} \cdot \mathbf{w}_{b(j)}) - \sum_{b=1}^B s_b
  \bar{w}_{b(j)}^{-1} (n_b - n_{tb})^{-1}
    \mathbf{1}'(\mathbf{x}_{b(j)} \cdot\mathbf{w}_{b(j)})  .\label{eq:1} 
\end{align}

Admittedly, this equation is rather an ugly duckling. But it gives us some better options for handling NAs,
while also preserving the covariance structure we'll need for the
multivariate inferentials. 

Operationally, our first step will be to \textit{align} the
$\mathbf{x}_{b}$ submatrices, ie to shift them in such a way that their
weighted means will be 0, yielding $\tilde{\mathbf{x}}_{b}$.  This simplifies \eqref{eq:1}  by causing its
second term to vanish.  
Then we'll apply the $\bar{w}_{b}^{-1}$
stratum-wise weight factors, by multiplying them through by weight
matrices $\tilde{\mathbf{w}}_{b}$, where $\tilde{\mathbf{w}}_{b(j)} = \mathbf{0} $ if
$\mathbf{w}_{b(j)}  = \mathbf{0} $, otherwise
$\tilde{\mathbf{w}}_{b(j)} = 
\bar{w}_{b(j)}^{-1} \mathbf{w}_{b(j)}$. 
So \eqref{eq:1} becomes
\begin{equation} \label{eq:2}
  d(\mathbf{Z}, \mathbf{x}) = \sum_{b=1}^B \frac{s_b}{h_b}
  \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
  \tilde{\mathbf{w}}_{b}), 
\end{equation}
where $\cdot $ indicates element-wise product. 

Any NAs in $\mathbf{x}_{b} $ become 0s in $\tilde{\mathbf{x}}$: in
effect, they're imputed to weighted stratum means.  In terms of its
effects on the values of $d(\mathbf{z}, \mathbf{x}_{(j)})$ or
$\mathbf{E}_{0}[d(\mathbf{Z}, \mathbf{x}_{(j)}) ]$, this imputation is
the same as omitting records that have NAs on the $j$-th $x$
variable.  To instead impute the mean of $\mathbf{x}_{(j)}$ across
strata $b$, as \texttt{xBalance} did in \texttt{RItools} version
0.1.14 and earlier, would have given the same values for $d(\mathbf{z}, \mathbf{x}_{(j)})$ or
$\mathbf{E}_{0}[d(\mathbf{Z}, \mathbf{x}_{(j)}) ]$, but would lead to
somewhat larger calculated values of $\mathrm{Var}_{0}[d(\mathbf{Z}_{b},
\mathbf{x}_{b(j)}) ]$, and in turn $\mathrm{Var}_{0}[d(\mathbf{Z},
\mathbf{x}_{(j)}) ]$: \textit{stratum}-mean imputation is
variance-minimizing, with the end result that the overall balance
check is more sensitive than it otherwise would be.  (Hansen \& Bowers
[\citeyear{hansen:bowers:2008}] give formulas for these moments.) 

Some conventions about stratum weighting, from \citet{hansen:bowers:2008}:
\begin{enumerate}
\item Although $\{h_{b}\}$ is not normalized to sum to 1, it's assumed
  that $\{s_{b} \}$ is. \label{item:1}
\item Expression \eqref{eq:2} somewhat obscures the important
  expectation that the unit weights $w_{bi}$ should play a role in
  determining the stratum weights.  For instance, for the default
  weighting suggested by H\&B 2008, one should have $s_{b} \propto
  \bar{w}_{b}h_{b}$.\label{item:2}
\item Stratum weights are presumed to be the same for all covariates.
  So the $\bar{w}_{b}$ figuring in a stratum weighting might be based
  on unit weights without attention to NAs, for example.  
\item The inferential calcs assume that the weights don't vary by
  treatment assignment. This rules out effect of treatment weighting
  in the strict sense, at least as far as Inferentials are concerned
  and in the case that the unit weights vary within strata.
\end{enumerate}

Suppose that we were to  adopt the
semantic convention 
that the user will have communicated sample inclusion probabilities via the
element weights.  There's no additional role for stratum weights per
se; instead, in which case what remains to be factored in are the
inverse probabilities of assignment,
$\pi_{bi}=\mathbf{P}(Z_{bi} = 1)$.  Relaxing \ref{item:1}--\ref{item:2} so
that we can set stratum weights $s_{b}$ to be proportional to the sum of sample inclusion weights
for stratum $b$, $\left(\sum_{i} w_{bi} \right) =
n_{b}\bar{w}_{b} $, in order to align with a target population for
inference, one has
\begin{align*}
  d(\mathbf{Z}, \mathbf{x}_{(j)}) &= \sum_{b=1}^B s_{b}\left\{  \mathbf{Z}_{b}'
                       (\mathbf{x}_{b(j)} \cdot \mathbf{w}_{b(j)})/(\bar{w}_{b(j)} n_{tb}) -
(\mathbf{1} -
                                    \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
                                    \mathbf{w}_{b(j)})/[\bar{w}_{b(j)}(n
                                    - n_{tb})] \right\}   \\
%% &= \sum_{b} \frac{s_{b}}{\bar{w}_{b}}  \left\{  \mathbf{Z}_{b}'
%%                        (\mathbf{x}_{b(j)} \cdot
%%   \tilde{\mathbf{w}}_{b(j)}) \frac{\bar{w}_{b}}{n_{tb}} -
%% (\mathbf{1} - \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
%%                                     \tilde{\mathbf{w}}_{b(j)})\frac{\bar{w}_{b}}{n_{b}
%%                                     - n_{tb}} \right\}   \\
&=      \sum_{b}  \frac{s_{b}}{n_{b}}\left\{  \frac{\mathbf{Z}_{b}'
                       (\mathbf{x}_{b(j)} \cdot
  \tilde{\mathbf{w}}_{b(j)}) }{\pi_{tb}} -
\frac{(\mathbf{1} -  \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
                                    \tilde{\mathbf{w}}_{b(j)}) }{ 1 -
  \pi_{tb}} \right\} \\
&= \left( \sum_{b} n_{b} \bar{w}_{b}\right)^{-1}     \sum_{b}  \bar{w}_{b}\left\{  \frac{\mathbf{Z}_{b}'
                       (\mathbf{x}_{b(j)} \cdot
  \tilde{\mathbf{w}}_{b(j)}) }{\pi_{tb}} -
\frac{(\mathbf{1} -  \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
                                    \tilde{\mathbf{w}}_{b(j)}) }{ 1 -
  \pi_{tb}} \right\},\, \mathrm{or} \\
                                  &=     \left( \sum_{b} n_{b} \bar{w}_{b}\right)^{-1}  \sum_{b}  \frac{\bar{w}_{b}}{\bar{w}_{b(j)}}\left\{  \frac{\mathbf{Z}_{b}'
                       (\mathbf{x}_{b(j)} \cdot {\mathbf{w}}_{b(j)})}{\pi_{tb}} -
\frac{(\mathbf{1} -  \mathbf{Z}_{b})'(\mathbf{x}_{b(j)}\cdot
                                    {\mathbf{w}}_{b(j)})}{ 1 -
  \pi_{tb}} \right\}, 
\end{align*}
where the factor ${\bar{w}_{b}}/{\bar{w}_{b(j)}}$ is as would be suggested by an assumption of
missingness at random within the stratum ($b$). As seen earlier, this is the same as to say 
\begin{equation*}
  d(\mathbf{Z}, \mathbf{x}) = \frac{s_{b}}{h_{b}} \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
    \tilde{\mathbf{w}}_{b}) = \left( \sum_{b} n_{b} \bar{w}_{b}\right)^{-1} \frac{n_{b}\bar{w}_{b}}{h_{b}} \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
    \tilde{\mathbf{w}}_{b}) . 
\end{equation*}
Perhaps these should be the default stratum weights for univariate
inferentials.  They might even be enforced, ie removed from user
control, eventually. But only for univariate inferentials; for multivariate
inferentials we might be better advised to stick with the \citet{hansen:bowers:2008}
recommendation that $s_{b} \propto h_{b} \bar{w}_{b}$. 
%% \begin{align*}
%%   d(\mathbf{Z}, \mathbf{x}) &= \sum_{b} \bar{w}_{b}\left\{  \frac{\mathbf{Z}_{b}'
%%                        (\mathbf{x}_{b} \cdot \tilde{\mathbf{w}}_{b})}{\pi_{tb}} -
%% \frac{(\mathbf{1} -  \mathbf{Z}_{b})'(\mathbf{x}_{b}\cdot
%%                                     \tilde{\mathbf{w}}_{b})}{ 1 -  \pi_{tb}} \right\} \\
%%   &=  \sum_{b} \bar{w}_{b}\left\{ \mathbf{Z}_{b}'
%%                        (\mathbf{x}_{b} \cdot \tilde{\mathbf{w}}_{b})
%%     (\pi_{tb}^{-1} + (1-\pi_{tb})^{-1}) - \frac{\mathbf{1}'(\mathbf{x}_{b}\cdot
%%                                     \tilde{\mathbf{w}}_{b})}{ 1 -
%%     \pi_{tb}} \right\} \\
%%   & = \sum_{b} \bar{w}_{b} (\pi_{tb}^{-1} + (1-\pi_{tb})^{-1})
%%     \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
%%     \tilde{\mathbf{w}}_{b}) \\
%%   &= \sum_{b} n_{b}\bar{w}_{b} (n_{tb}^{-1} + (n_{b} - n_{tb})^{-1})   \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
%%     \tilde{\mathbf{w}}_{b}) \\
%%   &= \sum_{b} \frac{n_{b}\bar{w}_{b}}{h_{b}}   \mathbf{Z}_{b}' (\tilde{\mathbf{x}}_{b} \cdot
%%     \tilde{\mathbf{w}}_{b}).
%% \end{align*}

Additional notes:
\begin{itemize}
\item The reason to keep $\tilde{\mathbf{x}}$ and $\tilde{\mathbf{w}} $
  separate, instead of rolling them into one, is to be able to apply a
  post-alignment transformation to the $x$es.  (E.g., take ranks, as
  in the Hodges-Lehmann aligned rank statistic.) 
\item Speaking of aligned ranks, when \citet{small:etal:2007} used
  them in a cluster randomized study, they aligned and transformed to
  ranks \textit{prior to} aggregating within the cluster.  Something I hope
  we'll enable soon (\#64).
\item That said, the weight normalization
  $w \mapsto \tilde{w} $ and covariate alignment $x \mapsto \tilde{x}$  
  have the property that you can apply them either before or after aggregating to the cluster
  level, with the same result. 
\item The advantage of imputation as opposed to simple omission is to
preserve the common structure across $x$ variables, which will in
general have different missingness patterns. This in turn is needed
for multivariate inferentials.
\end{itemize}




\subsection{Multivariate inferentials}

Need to impute missings here rather than omit them, in order to have
consistent data dimensions across vars. Although differences among
treatment and control HT estimates are blind to the value chosen for
imputations, covariances are not.  Imputing to the stratum mean
minimizes the variance of Z-effect along the imputed variable. 

I think we should hard code the use of ``harmonic'' weights\ldots


\bibliographystyle{plainnat}
%\bibliography{abbrev_long,causalinference,computing,misc}
\begin{thebibliography}{2}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Hansen and Bowers(2008)]{hansen:bowers:2008}
Ben~B. Hansen and Jake Bowers.
\newblock Covariate balance in simple, stratified and clustered comparative
  studies. \newblock \textit{Statistical Science}
\newblock 23\penalty0 (2):\penalty0 219--236, 2008.

\bibitem[Small et~al.(2008)Small, Ten~Have, and Rosenbaum]{small:etal:2007}
Dylan Small, Thomas~R. Ten~Have, and Paul Rosenbaum.
\newblock Randomization inference in a group-randomized trial of treatments for
  depression: covariate adjustment, noncompliance and quantile effects.
\newblock \textit{Journal of the American Statistical Association}
\newblock 103\penalty0 (481):\penalty0 271--279, 2008.
\newblock ISSN 0162-1459.

\end{thebibliography}

\end{document}
